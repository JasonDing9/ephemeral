{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arvind/miniconda3/envs/treehacks24/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"clarify\", \"email\", \"link\", \"schedule\", \"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 768])\n"
     ]
    }
   ],
   "source": [
    "# Walk through all files in a directory\n",
    "import os\n",
    "lines = []\n",
    "for class_ in classes:\n",
    "    # Read contents of file\n",
    "    with open('data/action_classification/' + class_ + '.txt', 'r') as f:\n",
    "        lines += f.readlines()\n",
    "\n",
    "inputs = encoder.encode(lines)\n",
    "inputs = torch.Tensor(inputs)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 5])\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for class_ in classes:\n",
    "    output_1he = torch.Tensor([0] * len(classes))\n",
    "    output_1he[classes.index(class_)] = 1\n",
    "    for i in range(100):\n",
    "        outputs.append(output_1he)\n",
    "\n",
    "outputs = torch.stack(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "inputs_train, inputs_test, outputs_train, outputs_test = train_test_split(inputs, outputs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActionClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(768, 384)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(384, 384)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(384, 384)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.fc4 = nn.Linear(384, 384)\n",
    "        self.dropout4 = nn.Dropout(0.2)\n",
    "        self.fc5 = nn.Linear(384, len(classes))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.gelu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.gelu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.gelu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.gelu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = F.gelu(self.fc5(x))\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = ActionClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 1.6092833280563354 train acc: 0.2150000035762787 test loss: 1.6100573539733887 best test loss: 1.6100573539733887 test acc: 0.14000000059604645\n",
      "Epoch 100 train loss: 1.4280565977096558 train acc: 0.4449999928474426 test loss: 1.5340031385421753 best test loss: 1.5340031385421753 test acc: 0.27000001072883606\n",
      "Epoch 200 train loss: 1.0811355113983154 train acc: 0.8450000286102295 test loss: 1.1846754550933838 best test loss: 1.1846754550933838 test acc: 0.75\n",
      "Epoch 300 train loss: 0.9466697573661804 train acc: 0.9599999785423279 test loss: 1.0640063285827637 best test loss: 1.058962345123291 test acc: 0.8500000238418579\n",
      "Epoch 400 train loss: 0.9405715465545654 train acc: 0.9649999737739563 test loss: 1.0655317306518555 best test loss: 1.0533347129821777 test acc: 0.8299999833106995\n",
      "Epoch 500 train loss: 0.9352471232414246 train acc: 0.9700000286102295 test loss: 1.0620434284210205 best test loss: 1.0394728183746338 test acc: 0.8399999737739563\n",
      "Epoch 600 train loss: 0.9341735243797302 train acc: 0.9700000286102295 test loss: 1.0683172941207886 best test loss: 1.0394728183746338 test acc: 0.8199999928474426\n",
      "Epoch 700 train loss: 0.9322068691253662 train acc: 0.9725000262260437 test loss: 1.0514086484909058 best test loss: 1.0330356359481812 test acc: 0.8399999737739563\n",
      "Epoch 800 train loss: 0.9323719143867493 train acc: 0.9725000262260437 test loss: 1.0543882846832275 best test loss: 1.0313228368759155 test acc: 0.8500000238418579\n",
      "Epoch 900 train loss: 0.9322285652160645 train acc: 0.9725000262260437 test loss: 1.0480798482894897 best test loss: 1.029375433921814 test acc: 0.8399999737739563\n",
      "Epoch 1000 train loss: 0.9323561191558838 train acc: 0.9725000262260437 test loss: 1.053602933883667 best test loss: 1.0289909839630127 test acc: 0.8500000238418579\n",
      "Epoch 1100 train loss: 0.9322139024734497 train acc: 0.9725000262260437 test loss: 1.0538463592529297 best test loss: 1.0289909839630127 test acc: 0.8500000238418579\n",
      "Epoch 1200 train loss: 0.932071328163147 train acc: 0.9725000262260437 test loss: 1.0475562810897827 best test loss: 1.0289909839630127 test acc: 0.8600000143051147\n",
      "Epoch 1300 train loss: 0.9323128461837769 train acc: 0.9725000262260437 test loss: 1.0555261373519897 best test loss: 1.0289909839630127 test acc: 0.8399999737739563\n",
      "Epoch 1400 train loss: 0.9321897029876709 train acc: 0.9725000262260437 test loss: 1.0443801879882812 best test loss: 1.0289909839630127 test acc: 0.8600000143051147\n",
      "Epoch 1500 train loss: 0.9321738481521606 train acc: 0.9725000262260437 test loss: 1.0419785976409912 best test loss: 1.0289909839630127 test acc: 0.8600000143051147\n",
      "Epoch 1600 train loss: 0.932170033454895 train acc: 0.9725000262260437 test loss: 1.0438518524169922 best test loss: 1.0289909839630127 test acc: 0.8600000143051147\n",
      "Epoch 1700 train loss: 0.9321392178535461 train acc: 0.9725000262260437 test loss: 1.0517369508743286 best test loss: 1.0272886753082275 test acc: 0.8500000238418579\n",
      "Epoch 1800 train loss: 0.9321588277816772 train acc: 0.9725000262260437 test loss: 1.0507280826568604 best test loss: 1.0272886753082275 test acc: 0.8500000238418579\n",
      "Epoch 1900 train loss: 0.9321890473365784 train acc: 0.9725000262260437 test loss: 1.0572786331176758 best test loss: 1.0272886753082275 test acc: 0.8399999737739563\n",
      "Epoch 2000 train loss: 0.9320713877677917 train acc: 0.9725000262260437 test loss: 1.0473911762237549 best test loss: 1.0272886753082275 test acc: 0.8600000143051147\n",
      "Epoch 2100 train loss: 0.9321746826171875 train acc: 0.9725000262260437 test loss: 1.048294186592102 best test loss: 1.027022123336792 test acc: 0.8500000238418579\n",
      "Epoch 2200 train loss: 0.932081401348114 train acc: 0.9725000262260437 test loss: 1.040696382522583 best test loss: 1.027022123336792 test acc: 0.8600000143051147\n",
      "Epoch 2300 train loss: 0.9322398900985718 train acc: 0.9725000262260437 test loss: 1.049977421760559 best test loss: 1.027022123336792 test acc: 0.8500000238418579\n",
      "Epoch 2400 train loss: 0.9320676326751709 train acc: 0.9725000262260437 test loss: 1.0548255443572998 best test loss: 1.027022123336792 test acc: 0.8500000238418579\n",
      "Epoch 2500 train loss: 0.9249104261398315 train acc: 0.9800000190734863 test loss: 1.0420907735824585 best test loss: 1.027022123336792 test acc: 0.8700000047683716\n",
      "Epoch 2600 train loss: 0.9248042106628418 train acc: 0.9800000190734863 test loss: 1.0365933179855347 best test loss: 1.027022123336792 test acc: 0.8700000047683716\n",
      "Epoch 2700 train loss: 0.9248156547546387 train acc: 0.9800000190734863 test loss: 1.0357866287231445 best test loss: 1.027022123336792 test acc: 0.8700000047683716\n",
      "Epoch 2800 train loss: 0.9246905446052551 train acc: 0.9800000190734863 test loss: 1.0452730655670166 best test loss: 1.027022123336792 test acc: 0.8600000143051147\n",
      "Epoch 2900 train loss: 0.9246927499771118 train acc: 0.9800000190734863 test loss: 1.0511504411697388 best test loss: 1.027022123336792 test acc: 0.8600000143051147\n",
      "Epoch 3000 train loss: 0.9247867465019226 train acc: 0.9800000190734863 test loss: 1.0567759275436401 best test loss: 1.025773048400879 test acc: 0.8500000238418579\n",
      "Epoch 3100 train loss: 0.9247182607650757 train acc: 0.9800000190734863 test loss: 1.055917501449585 best test loss: 1.025773048400879 test acc: 0.8500000238418579\n",
      "Epoch 3200 train loss: 0.9247459173202515 train acc: 0.9800000190734863 test loss: 1.0357052087783813 best test loss: 1.025773048400879 test acc: 0.8700000047683716\n",
      "Epoch 3300 train loss: 0.9248529672622681 train acc: 0.9800000190734863 test loss: 1.039318323135376 best test loss: 1.025773048400879 test acc: 0.8700000047683716\n",
      "Epoch 3400 train loss: 0.924816906452179 train acc: 0.9800000190734863 test loss: 1.0403404235839844 best test loss: 1.025773048400879 test acc: 0.8600000143051147\n",
      "Epoch 3500 train loss: 0.9248270988464355 train acc: 0.9800000190734863 test loss: 1.0388895273208618 best test loss: 1.025773048400879 test acc: 0.8700000047683716\n",
      "Epoch 3600 train loss: 0.9246839880943298 train acc: 0.9800000190734863 test loss: 1.0344836711883545 best test loss: 1.025773048400879 test acc: 0.8700000047683716\n",
      "Epoch 3700 train loss: 0.9246994256973267 train acc: 0.9800000190734863 test loss: 1.0467406511306763 best test loss: 1.025773048400879 test acc: 0.8600000143051147\n",
      "Epoch 3800 train loss: 0.9247229099273682 train acc: 0.9800000190734863 test loss: 1.0246165990829468 best test loss: 1.0246165990829468 test acc: 0.8799999952316284\n",
      "Epoch 3900 train loss: 0.9223735928535461 train acc: 0.9825000166893005 test loss: 1.0360790491104126 best test loss: 1.0246165990829468 test acc: 0.8700000047683716\n",
      "Epoch 4000 train loss: 0.9222316145896912 train acc: 0.9825000166893005 test loss: 1.037499189376831 best test loss: 1.0243583917617798 test acc: 0.8600000143051147\n",
      "Epoch 4100 train loss: 0.9221926331520081 train acc: 0.9825000166893005 test loss: 1.0370854139328003 best test loss: 1.0240039825439453 test acc: 0.8700000047683716\n",
      "Epoch 4200 train loss: 0.9222180843353271 train acc: 0.9825000166893005 test loss: 1.0508975982666016 best test loss: 1.0235306024551392 test acc: 0.8600000143051147\n",
      "Epoch 4300 train loss: 0.9221984148025513 train acc: 0.9825000166893005 test loss: 1.0495672225952148 best test loss: 1.0223525762557983 test acc: 0.8600000143051147\n",
      "Epoch 4400 train loss: 0.9172393083572388 train acc: 0.987500011920929 test loss: 1.0231025218963623 best test loss: 1.0223525762557983 test acc: 0.8899999856948853\n",
      "Epoch 4500 train loss: 0.9177854061126709 train acc: 0.987500011920929 test loss: 1.039347529411316 best test loss: 1.0223525762557983 test acc: 0.8700000047683716\n",
      "Epoch 4600 train loss: 0.9171774983406067 train acc: 0.987500011920929 test loss: 1.0506658554077148 best test loss: 1.0223525762557983 test acc: 0.8500000238418579\n",
      "Epoch 4700 train loss: 0.9172064065933228 train acc: 0.987500011920929 test loss: 1.0273884534835815 best test loss: 1.0204423666000366 test acc: 0.8799999952316284\n",
      "Epoch 4800 train loss: 0.9172104001045227 train acc: 0.987500011920929 test loss: 1.0537164211273193 best test loss: 1.0204423666000366 test acc: 0.8500000238418579\n",
      "Epoch 4900 train loss: 0.9172250628471375 train acc: 0.987500011920929 test loss: 1.0434471368789673 best test loss: 1.0204423666000366 test acc: 0.8600000143051147\n"
     ]
    }
   ],
   "source": [
    "best_test_loss = float('inf')\n",
    "for epoch in range(5000):\n",
    "    optimizer.zero_grad()\n",
    "    preds_train = model(inputs_train)\n",
    "    train_loss = criterion(preds_train, outputs_train)\n",
    "    train_loss.backward()\n",
    "    train_acc = (preds_train.argmax(1) == outputs_train.argmax(1)).float().mean()\n",
    "    optimizer.step()\n",
    "\n",
    "    preds_test = model(inputs_test)\n",
    "    test_loss = criterion(preds_test, outputs_test)\n",
    "    test_acc = (preds_test.argmax(1) == outputs_test.argmax(1)).float().mean()\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'server/action_classifier.pt')\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {} train loss: {} train acc: {} test loss: {} best test loss: {} test acc: {}'.format(epoch, train_loss, train_acc, test_loss, best_test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActionClassifier(\n",
       "  (fc1): Linear(in_features=768, out_features=384, bias=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=384, out_features=384, bias=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (fc3): Linear(in_features=384, out_features=384, bias=True)\n",
       "  (dropout3): Dropout(p=0.2, inplace=False)\n",
       "  (fc4): Linear(in_features=384, out_features=384, bias=True)\n",
       "  (dropout4): Dropout(p=0.2, inplace=False)\n",
       "  (fc5): Linear(in_features=384, out_features=5, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_classifier = ActionClassifier()\n",
    "action_classifier.load_state_dict(torch.load('server/action_classifier.pt'))\n",
    "action_classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(text):\n",
    "    input_ = torch.Tensor(encoder.encode([text]))\n",
    "    output = action_classifier(input_)\n",
    "    print(output)\n",
    "    return classes[output.argmax(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4797e-07, 2.1970e-04, 1.4797e-07, 9.9978e-01, 1.4797e-07]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'schedule'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer('Let\\'s all meet sometime to discuss sprint planning for this project. Who\\'s available?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treehacks24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
